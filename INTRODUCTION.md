# 개요

포세이돈은 온디바이스 TinyML을 활용한 QRAME 프로토콜의 내부 보안 AI 모델입니다. 이 모델은 패킷 엔트로피, 타이밍 변동, 양자 노이즈를 분석하며, 양자 시뮬레이터와 실제 공격 데이터셋을 기반으로
훈련됩니다. 이러한 기능에 따라 이상 패킷 발견 시 즉시 PQC(Post-Quantum Cryptography) 알고리즘의 보안 수준을 상향 조정하고 그룹 경고를 발송하는 역할을 합니다.

# 데이터셋

포세이돈이 학습에 사용한 데이터셋은 NetFlow 유형의 NIDS(Network Intrusion Detection System, NIDS) 데이터셋입니다.
문헌 [NetFlow Datasets for Machine Learning-based Network Intrusion Detection Systems](https://arxiv.org/pdf/2011.09144)(
이하 "$\text{Sarhan et al. (2020)}$"라고 함.)에 따르면, NF-UNSW-NB15, NF-BoT-IoT, NF-ToN-IoT, NF-CSE-CIC-IDS2018 데이터셋은 패킷 헤더에서
추출된 피처(features)를 포함하며, 바이너리 또는 다중 클래스[^5] 분류를 지원합니다. 이러한
피처는 [섀넌(Claude Shannon)의 엔트로피](https://people.math.harvard.edu/~ctm/home/text/others/shannon/entropy/entropy.pdf)와 폰
노이만(von Neumann)의 엔트로피를 계산하기에 적합하며, 표준편차에
기반한 타이밍 변동과 양자 노이즈를 통합할 수 있습니다.

# 학습 가능성의 수학적 기반

학습 가능성은 수학적 기반에서 유래합니다. 데이터셋의 플로우 피처(flow features)를 입력 벡터 $\mathbf{X}$로 표현하면 모델은 확률 분포 $p(y\vert\mathbf{X})$를 학습하여 공격
여부를 예측합니다. 양자 시뮬레이터를 통해 노이즈 채널(후술)을 적용하면 밀도 행렬 $\rho$에 대한 크라우스(Kraus) 표현이 도입되어 다음과 같습니다.
$$
\rho' = \sum_k K_k \rho K_k^\dagger
$$
$\rho'$는 연산 후(입력에 따른 출력, 즉 결과)의 밀도 행렬(density matrix)임을 의미하며, $\xi(\rho)$ 로 표현하기도 합니다. $K_k$는 노이즈 연산자다. 이는 고전적 NetFlow
데이터를 [양자 블랙박스(quantum blackbox)](https://arxiv.org/pdf/quant-ph/9610001)로 모델링하여 실시간 이상 탐지를 강화합니다.

# 학습 과정

학습 과정을 소개하겠습니다.

## 데이터 준비 및 전처리

대용량 `.csv` 파일을 청크(chunk) 기반으로 로드한 후, 결측값(missing values) 처리와 정규화(normalization 또는 standardization)를 수행합니다. 대용량 `csv` 파일은
`pandas` 라이브러리를 통해 처리됩니다. 청크 기반 로드는 대용량 데이터 처리에서 표준이며, 후속 전처리(결측값 처리, 정규화)를 청크 단위로 적용 가능합니다.

결측값은 청크별로 평균(mean)/중앙값(median) 대체 또는 삭제로 처리할 수 있으며, 정규화는 각 청크에 적용됩니다. 다만 전체 데이터셋의 통계가 필요한 경우, 청크 기반 처리가 부정확할 수 있기 때문에 두
번의 패스(전체 데이터의 통계 계산 후 적용)를 고려해야 합니다. 다음의 방법을 통해 결측값을 처리할 수 있습니다.

## 피처 엔지니어링

NetFlow 피처를 엔트로피와 노이즈로 확장합니다. 섀넌의 엔트로피는 다음과 같이 표현됩니다.
$$
H(X) = - \sum_i p(x_i)\log_2 p(x_i)
$$
폰 노이만의 엔트로피는 다음과 같이 표현됩니다.
$$
S(\rho) = - \text{Tr}(\rho \log_2 \rho)
$$
타이밍 변동은 현재 데이터와 다음 데이터의 도착 간격(inter-arrival times)의 표준편차 $\sigma$로 계산되며, qutip-jax 라이브러리를 통해 플로우 데이터를 밀도 행렬로 매핑하고
비트-플립/페이즈-플립 노이즈를 시뮬레이션하여 새로운
피처를 생성합니다.

## 모델 훈련

JAX는 구글에서 개발된 라이브러리로, NumPy와 유사한 API(numpy-like)를 제공하며 자동 미분과 JIT(Just-In-Time) 컴파일을 지원하여 고성능 신경망 훈련에 적합합니다. MLP(
Multo-Layer Perceptron)나 CNN(Convolutional Neural Network)은 JAX의 flax나 equinox 같은 라이브러리를 통해 쉽게 구현할 수 있으며, GPU/TPU
가속이 가능합니다.

모델이 잘못된 예측을 어떻게 개선할지에 대한 기준을 만들기 위해 손실 함수(loss function)가 필요합니다. 이는 머신러닝 모델 훈련에서 필수적인 요소입니다. 모델이 입력 데이터에 대해 예측한
결과 $\hat{y}$와 실제 정답 $y$ 사이의 차이를 수량화하는 역할을 합니다. 이 차이를 최소화함으로써 모델의 성능을 향상시킵니다.

예로, 분류 문제에서 크로스-엔트로피(cross-entropy) 손실 함수는 다음과 같이 정의됩니다.
$$
L = - \sum y \log \hat{y}
$$
손실 함수는 모델의 오류를 객관적으로 평가하는 지표로 작용하며, 과적합(overfitting)이나 일반화(generalization) 문제를 진단하는 데도 활용됩니다.

이러한 손실 함수는 Adam 옵티마이저와 경사 하강법(gradient descent)의 기반이 됩니다. 경사 하강법은 손실 함수의 기울기(gradient)를 계산하여 모델 파라미터 $\theta$를 업데이트하는
최적화
알고리즘입니다. 수학적으로 파라미터 업데이트는 다음과 같습니다.
$$
\theta \leftarrow \theta - \eta\nabla L(\theta)
$$
여기서 $\eta$는 학습률(learning rate), $\nabla L(\theta)$은 손실 함수의 기울기입니다. Adam 옵티마이저는 경사 하강법의 변형으로, 모멘텀(momentum)과 적응형 학습률(
RMSProp)을 결합하여 더 안정적이고 빠른 수렴을 제공합니다. 손실 함수가 기울기를 제공하지 않으면 Adam이 작동할 수 없으므로 이 셋은 밀접하게 연결되어 있습니다. 즉, 손실 함수가 오류를 정의하면,
Adam과
경사 하강법이 그 오류를 줄이는 방향으로 파라미터를 조정합니다.

전체 과정에서 에폭(epoch)이라는 단위가 중요시됩니다. 이는 모델 훈련에서 전체 데이터셋을 한 번 완전히 처리하는 단위를 의미하며, "~에폭 동안" 반복되는 것은 배치(batch) 단위의 예측 계산(forward
pass), 손실 함수 평가, 기울기 계산(backward pass), 그리고 파라미터 업데이트입니다. 예를 들어, '10 에폭 동안 훈련' 한다는 말은 데이터셋을 10번 반복하여 훈련한다는 의미입니다. 이는 모델이
데이터 패턴을 점진적으로 학습하도록 하며, 과적합 방지를 위해 조기 종료(early stopping)와 함께 사용됩니다.

> 물론 반복 횟수가 많아질 수록 손실 값이 감소하지만, 무한 반복은 비효율적입니다.

훈련의 마지막 단계에선 데이터 증강(data augmentation) 훈련을 수행합니다. 이는 훈련 데이터의 다양성을 인위적으로 증가시켜 모델의 일반화 능력을 높이는 기법입니다. "노이즈 추가"는 입력 데이터에
랜덤한
변형(가우시안 노이즈 같은.)을 더하는 것을 의미하며, 데이터셋이 부족하거나 과적합이 발생할 때 유용합니다. 예로 이미지 데이터에서 픽셀 값에 작은 랜덤 값을 더하면 모델이 노이즈에 강건(robust)해집니다.

> 여기서 언급된 "노이즈"는 머신러닝 맥락에서 가우시안 노이즈같은 일반적인 랜덤 변동을 가리키며, 양자 컴퓨팅의 양자 노이즈와 무관합니다.

## 평가 및 최적화

위 과정들을 통해 모델 훈련이 완료되면 모델 평가 지표인 ROC-AUC와 F1-score를 사용하여 평가합니다.

# QRAME 에서의 활용

포세이돈은 명백히 QRAME 프로토콜에서 AI 보조 계층에 사용됩니다. QRAME 프로토콜의 메쉬 네트워크(mesh network) 환경에서 발생하는 네트워크 트래픽 데이터를 주 입력으로 사용합니다. 이는 주로
NetFlow 기반의 플로우 피처로 구성되며, 중앙 서버 의존 없이 온디바이스에서 실시간으로 수집합니다.

포세이돈의 출력은 QRAME 적응형 키 합의와 메쉬 네트워킹에 직접 피드백되어 보안 탄력성을 제공합니다. QRAME는 PQXDH 기반으로 PQC 알고리즘을 사용하며, 포세이돈이 이를 보조합니다.

위협 점수가 높을 경우 PQC 알고리즘 레벨을 동적으로 업그레이드합니다. 예를 들어, 다음 공식에 포세이돈이 위협 점수를 입력하여 알고리즘을 전환합니다.
$$
\text{Security\_Level} = \alpha \cdot \text{Threat\_Score} + \beta \cdot \text{Network\_Latency} + \gamma \cdot \text{Battery\_Level}
$$
이는 네트워크 지연이나 배터리 상태를 고려한 적응형 결정입니다. 위 공식에는 $\alpha = 0.6, \beta = 0.25, \gamma = 0.15$같은 수치가 결정될 수 있습니다.

또한, 메쉬 네트워크에서 P2P 방식으로 그룹 참가자에게 그룹 경고를 전파할 수 있습니다. Merkel Tree를 통해 그룹 상태를 효율적으로 업데이트하며, 한 참가자의 탈퇴/위협 시 전체 재계산을 최소화합니다.

키 합의 과정(PQXDH 확장)에서 포세이돈 출력이 MeshSK(메쉬 공유 기) 도출에 반영되어 HNDL 공격을 방어합니다. 이상 탐지 시 래칫(Ratchet) 메커니즘을 강화하여 전방 보안(forward
secrecy)을 유지하며 키 합의 피드백을 수행합니다.

마지막으로, 포세이돈은 중앙 서버 없이 온디바이스에서 작동하는 것을 강조하겠습니다. 이는 이상 패킷 탐지 시 애플리케이션에서 허용 가능한 범위 만큼의(어쩌면 디바이스 자체) 보안을 제공한다. 이러한 점은 NIST
Level 5 보안을 목표로 한 장기적 안정성을 충분히 확보합니다.

# 정상 타입 바이너리 클래스

이 절에는 유동적으로 변경되는 리샘플링 후 데이터셋의 몇 가지 개별 데이터(클래스 등)를 기록했습니다. 모든 데이터셋은 NetFlow 형태를 가지기 때문에 개별 데이터셋의 피처는 모두 동일합니다. `Label`
클래스의 경우, $\text{정상 0} : \text{이상 1}$ 비율의 형태를 갖습니다. 이처럼 비율을 계산할 필요가 있는 경우, 한 쪽을 1 비율로 맞추기 위한 수학적인 기술을 포함하겠습니다.

앞서 언급드렸다시피, 사용하는 데이터셋은 **2025.10.23** 기준 다음의 네 가지입니다. (소수 클래스의) 오버샘플링 비율은 `0.4831882086330935`로 모두 동일합니다.

- NF-BoT-IoT-v3
    - **리샘플링 전**: `Label` $18,225 : 15,863,478 \quad (1 : 870.424)$
    - **리샘플링 후**: `Label` $7,674,464 : 15,863,478 \quad (1 : 2.067)$
- NF-CICIDS2018-v3
    - **리샘플링 전**: `Label` $17,514,626 : 2,600,903 \quad (1 : 0.148)$
    - **리샘플링 후**: `Label` $17,514,626 : 9,807,038 \quad (1 : 0.56)$
- NF-ToN-IoT-v3
    - **리샘플링 전**: `Label` $16,792,214 : 10,728,046 \quad (1 : 0.639)$
    - **리샘플링 후**: `Label` $16,792,214 : 9,807,038 \quad (1 : 0.56)$
- NF-UNSW-NB15-v3
    - **리샘플링 전**: `Label` $2,151,027 : 91,904 \quad (1 : 0.043)$
    - **리샘플링 후**: `Label` $2,151,027 : 1,086,847 \quad (1 : 0.505)$